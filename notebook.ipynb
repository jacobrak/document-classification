{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Transcriber's Note:\\nEvery effort has been mad...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“In a few moments Marianne, Solomin, Paul,\\n\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“Marianne knelt beside the sofa.… Nezhdanof\\n\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“Solomin raised Marianne's hand, her head\\n\\nl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“He now was no longer, but the hands of\\n\\nSol...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Transcriber's Note:\\nEvery effort has been mad...      0\n",
       "1  “In a few moments Marianne, Solomin, Paul,\\n\\n...      0\n",
       "2  “Marianne knelt beside the sofa.… Nezhdanof\\n\\...      0\n",
       "3  “Solomin raised Marianne's hand, her head\\n\\nl...      0\n",
       "4  “He now was no longer, but the hands of\\n\\nSol...      0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymongo\n",
    "import pandas as pd \n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"story_database\"]  # Database name\n",
    "collection = db[\"short_stories\"]\n",
    "\n",
    "documents = collection.find()\n",
    "\n",
    "df_raw = pd.DataFrame(list(documents))\n",
    "df_raw = df_raw[[\"text\", \"label\"]]\n",
    "df_raw.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the cleaning function\n",
    "def clean_text(text):\n",
    "\n",
    "    text = text.replace('\\n', ' ') \n",
    "    text = re.sub(r'=', '', text)  \n",
    "\n",
    "    # Keep only English alphabet characters and spaces \n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "\n",
    "    return text\n",
    "\n",
    "df_raw['cleaned_text'] = df_raw['text'].apply(clean_text)\n",
    "\n",
    "df = df_raw[[\"cleaned_text\", \"label\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86        36\n",
      "           1       0.85      1.00      0.92        51\n",
      "\n",
      "    accuracy                           0.90        87\n",
      "   macro avg       0.93      0.88      0.89        87\n",
      "weighted avg       0.91      0.90      0.89        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "df_shuffled = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "X = df_shuffled[\"cleaned_text\"]\n",
    "y = df_shuffled[\"label\"]\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)  # max_iter to ensure convergence\n",
    "clf.fit(X_train, y_train)\n",
    "        \n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "cleaned_data = (classification_report(y_test, y_pred))\n",
    "print(cleaned_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow this was a bit anticlimactic, lets mess the data up see if we get the same results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets not clean the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.71      0.83        41\n",
      "           1       0.79      1.00      0.88        46\n",
      "\n",
      "    accuracy                           0.86        87\n",
      "   macro avg       0.90      0.85      0.86        87\n",
      "weighted avg       0.89      0.86      0.86        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_shuffled = df_raw.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "X = df_shuffled[\"cleaned_text\"]\n",
    "y = df_shuffled[\"label\"]\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)  # max_iter to ensure convergence\n",
    "clf.fit(X_train, y_train)\n",
    "        \n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets add data, fakenews!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakenews = pd.read_csv(\"data/fake_news.csv\")\n",
    "fakenews.columns = [\"cleaned_text\", \"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([fakenews, df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.79      0.89        39\n",
      "           1       0.79      0.88      0.84        52\n",
      "           2       0.81      0.85      0.83        46\n",
      "\n",
      "    accuracy                           0.85       137\n",
      "   macro avg       0.87      0.84      0.85       137\n",
      "weighted avg       0.86      0.85      0.85       137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_shuffled = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "X = df_shuffled[\"cleaned_text\"]\n",
    "y = df_shuffled[\"label\"]\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)  # max_iter to ensure convergence\n",
    "clf.fit(X_train, y_train)\n",
    "        \n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31,  5,  3],\n",
       "       [ 0, 46,  6],\n",
       "       [ 0,  7, 39]], dtype=int64)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is the vectorizer that good?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
